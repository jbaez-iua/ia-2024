
---
marp: true
theme: default
class: invert
paginate: true
---

# Filosofía, Ética y Seguridad de la IA
## Capítulo 28

---

# Esquema

- Los Límites de la IA
- ¿Pueden las Máquinas Realmente Pensar?
- La Ética de la IA

---

# Los Límites de la IA

## Perspectiva de John Searle (1980)
- **IA Débil**: Las máquinas podrían actuar como si fueran inteligentes
- **IA Fuerte**: Las máquinas están realmente pensando de manera consciente

## El Argumento de la Informalidad
- El "argumento de la informalidad del comportamiento" de Turing
- El comportamiento humano es demasiado complejo para reglas formales

## IA Clásica (GOFAI)
- Diseño de agente lógico más simple
- Problema de la calificación
- Argumento de Dreyfus para agentes situados
- Enfoque de cognición corporizada

---

# Los Límites de la IA: El Argumento de la Discapacidad

- "Una máquina nunca podrá hacer X"
- Lista de X de Turing:
  - Ser amable, ingeniosa, hermosa, amistosa...
  - Tener iniciativa, sentido del humor...
  - Distinguir el bien del mal, cometer errores...
  - Enamorarse, disfrutar experiencias...
  - Aprender, usar palabras correctamente...
  - Ser autoconsciente, tener comportamiento diverso...
  - Hacer algo realmente nuevo

---

# Midiendo la IA: El Test de Turing

![bg right:40% 80%](https://upload.wikimedia.org/wikipedia/commons/e/e4/Turing_Test_version_3.png)

- Prueba conductual de inteligencia de máquinas
- Conversación de 5 minutos mediante mensajes escritos
- Programas notables:
  - ELIZA
  - MGONZ
  - NATACHATA
  - Eugene Goostman (engañó al 33% de los jueces)
- Competencias alternativas:
  - Ajedrez, Go, StarCraft II
  - Exámenes de ciencias de 8vo grado
  - Reconocimiento de imágenes

---

# ¿Pueden las Máquinas Realmente Pensar?

## El Argumento de la Habitación China

![bg right:40% 80%](https://upload.wikimedia.org/wikipedia/commons/e/e0/Chinese_room.png)

- Propuesto por John Searle
- Humano en una habitación con:
  - Libro de reglas en inglés
  - Pilas de papel con símbolos chinos
- Proceso:
  1. Recibir entrada en chino
  2. Seguir instrucciones en inglés
  3. Producir salida en chino
- Argumento: El humano no entiende chino, por lo tanto, las computadoras tampoco entienden al procesar información

---

# La Ética de la IA: Aspectos Positivos

![bg right:40% 80%](https://images.unsplash.com/photo-1507146426996-ef05306b995a?ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80)

- Salvar vidas a través de:
  - Diagnósticos médicos mejorados
  - Nuevos descubrimientos médicos
  - Mejor predicción de clima extremo
- Mejorando vidas:
  - IA para Acción Humanitaria de Microsoft
- Alimentando al mundo:
  - IA en gestión de cultivos
  - Optimización de la producción de alimentos

---

# La Ética de la IA: Aspectos Negativos

## Armas Autónomas Letales

![bg right:40% 70%](https://upload.wikimedia.org/wikipedia/commons/7/7f/IAI-Harop-Loitering-Munition.jpg)

- Definición de la ONU: Armas que seleccionan y atacan objetivos sin supervisión humana
- Ejemplo: Misil Harop de Israel
- El debate incluye:
  - Aspectos legales
  - Preocupaciones éticas
  - Consideraciones prácticas
- Campaña para Detener los Robots Asesinos
- IA como tecnología de doble uso

---

# La Ética de la IA: Vigilancia, Seguridad y Privacidad

![bg right:40% 80%](https://images.unsplash.com/photo-1516686824740-a91c90f53a4f?ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80)

- Cámaras de vigilancia: 350M en China, 70M en EE.UU. (2018)
- Desafíos de ciberseguridad
- Recolección de datos por gobiernos y corporaciones
- Leyes de protección de privacidad (HIPAA, FERPA)
- Técnicas de des-identificación
- Aprendizaje federado
- Agregación segura

---

# La Ética de la IA: Equidad y Sesgo

![bg right:40% 80%](https://images.unsplash.com/photo-1551817958-604beba8a3fc?ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80)

## Seis Conceptos de Equidad:
1. Equidad individual
2. Equidad grupal
3. Equidad por desconocimiento
4. Igualdad de resultados
5. Igualdad de oportunidades
6. Impacto igualitario

## Caso de Estudio COMPAS
- Sistema de puntuación de reincidencia
- Oportunidad desigual entre razas

---

# La Ética de la IA: Mejores Prácticas para la Equidad

1. Colaborar con científicos sociales y expertos en el dominio
2. Fomentar equipos de desarrollo diversos
3. Definir claramente los grupos respaldados
4. Incorporar la equidad en las funciones objetivo
5. Examinar los datos en busca de prejuicios y correlaciones
6. Asegurar la calidad de las anotaciones humanas
7. Rastrear métricas para subgrupos
8. Incluir pruebas de sistema diversas
9. Implementar bucles de retroalimentación para problemas de equidad

---

# La Ética de la IA: Confianza y Transparencia

![bg right:40% 80%](https://images.unsplash.com/photo-1506485927884-1900e30e912d?ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80)

- Proceso de Verificación y Validación (V&V)
- Estándares de certificación y seguridad
- IEEE P7001: Diseño ético para sistemas de IA
- IA Explicable (XAI)
  - Comprensible
  - Precisa
  - Completa
  - Específica

---

# La Ética de la IA: El Futuro del Trabajo

![bg right:40% 80%](https://images.unsplash.com/photo-1513192800243-82222f3edb38?ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80)

- Reducción inmediata en el empleo
- Aumento en la automatización física con robots
- Cambio en la relación trabajador-jubilado
- Desafíos debido al ritmo del cambio

---

# La Ética de la IA: Derechos de los Robots

![bg right:40% 80%](https://images.unsplash.com/photo-1546776310-eef45dd6d63c?ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80)

- Consideraciones si los robots pueden sentir dolor o temer a la muerte
- Cuestiones de personalidad y derechos
- Preocupaciones éticas sobre la reprogramación
- Dilema de los derechos de voto
- Ernie Davis: Evitar la conciencia en robots

---

# La Ética de la IA: Seguridad de la IA

![bg right:40% 80%](https://images.unsplash.com/photo-1502811744755-16bf93952d97?ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80)

- Diseño de bajo impacto
- Ejemplos de manipulación del sistema
- Fallas de especificación
- Problema de alineación de valores

---

# Resumen

- IA Débil vs IA Fuerte
- Imperativos éticos en el desarrollo de IA
- Equidad, confianza y transparencia en sistemas de IA
- Múltiples aspectos de la equidad
- Impacto de la automatización en el trabajo y la sociedad

---

```

## Notas sobre la traducción

1. "Vos" y conjugaciones correspondientes: En esta traducción, se mantuvo un tono formal y profesional, por lo que no se utilizó el "vos" característico del español argentino. En un contexto académico o profesional en Argentina, es común utilizar el "usted" o formas impersonales.

2. Términos técnicos: Se mantuvieron en su forma original términos como "Weak AI", "Strong AI", "Good Old-Fashioned AI (GOFAI)", "Explainable AI (XAI)", ya que son ampliamente reconocidos en la comunidad técnica y académica argentina.

3. Siglas: Se mantuvieron siglas como "HIPAA" y "FERPA", ya que se refieren a leyes específicas de EE.UU. y no tienen un equivalente directo en Argentina.

4. Nombres propios: Se mantuvieron en su forma original nombres como "John Searle", "Turing", "Dreyfus", "ELIZA", "MGONZ", "NATACHATA", "Eugene Goostman", ya que son referencias específicas a personas o programas.

5. Conceptos académicos: Se tradujeron conceptos como "embodied cognition" a "cognición corporizada", que es el término utilizado en la literatura académica en español.

## Aspectos desafiantes de la traducción

1. La traducción de "Argument from Disability" como "Argumento de la Discapacidad" podría ser sensible en algunos contextos. Se mantuvo por ser una traducción directa del concepto filosófico, pero en un contexto más amplio podría requerir una explicación adicional.

2. La traducción de términos técnicos específicos de IA, como "low impact design" o "gaming the system", requirió un equilibrio entre la precisión técnica y la comprensibilidad para una audiencia argentina.

3. Algunos conceptos, como "fairness" en el contexto de IA, no tienen una traducción única y establecida en español. Se optó por "equidad", pero en algunos contextos podría ser necesario utilizar "justicia" o incluso mantener el término en inglés.

4. La traducción de "Campaign to Stop Killer Robots" como "Campaña para Detener los Robots Asesinos" mantiene el impacto del original, pero podría sonar sensacionalista en un contexto académico argentino. Sin embargo, se mantuvo por ser el nombre oficial de la campaña.

5. La adaptación de ejemplos y estadísticas específicas de otros países (como las cámaras de vigilancia en China y EE.UU.) podría requerir contextualización adicional para una audiencia argentina, aunque se mantuvieron por su relevancia global en el tema de la ética de la IA.